---
title: Tiny Llama | Getting Started with Open WebUI
description: A step-by-step guide to getting started with Open WebUI, including initial setup, model selection, and image inference via chat.
---
<h1 id="getting-started-with-open-webui" class="mat-card-title">Getting Started with Open WebUI</h1>
<div class="card-frame">
    <div class="mat-card">
        <h2 id="table-of-contents">Table of Contents</h2>
        <ul class="toc">
            <li><a href="#getting-started-with-open-webui">Getting Started with Open WebUI</a></li>
            <li><a href="#initial-setup">Initial Setup</a>
                <ul>
                    <li><a href="#accessing-open-webui">Accessing Open WebUI</a></li>
                    <li><a href="#creating-an-account">Creating an Account</a></li>
                    <li><a href="#resolving-account-issues">Resolving Account Issues</a></li>
                </ul>
            </li>
            <li><a href="#account-activation">Account Activation</a>
                <ul>
                    <li><a href="#access-the-administrator-panel">Access the Administrator Panel</a></li>
                    <li><a href="#step-2-promote-the-pending-user">Step 2: Promote the Pending User</a></li>
                </ul>
            </li>
            <li><a href="#how-to-chat">How to Chat</a>
                <ul>
                    <li><a href="#step-1-starting-a-new-conversation">Step 1: Starting a New Conversation</a>
                    </li>
                    <li><a href="#step-2-selecting-a-model">Step 2: Selecting a Model</a></li>
                    <li><a href="#step-3-sending-messages">Step 3: Sending Messages</a></li>
                    <li><a href="#step-4-submitting-messages">Step 4: Submitting Messages</a></li>
                </ul>
            </li>
            <li><a href="#model-selection">Model Selection</a>
                <ul>
                    <li><a href="#available-models">Available Models</a>
                        <ul>
                            <li><a href="#llama3-1">llama3.1</a></li>
                            <li><a href="#hermes-2-theta-llama-3">hermes-2-Theta-llama-3</a></li>
                            <li><a href="#llava-phi3">llava-phi3</a></li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><a href="#image-inference-via-chat">Image Inference via Chat</a>
                <ul>
                    <li><a href="#using-lmms-for-image-inference">Using LMMs for Image Inference</a></li>
                </ul>
            </li>
            <li><a href="#image-generation-via-chat">Image Generation via Chat</a>
                <ul>
                    <li><a href="#generating-images-with-diffusion-models-and-llms">Generating Images with
                            Diffusion Models and LLMs</a></li>
                </ul>
            </li>
        </ul>
        <h2 id="initial-setup">Initial Setup</h2>
        <h3 id="accessing-open-webui">Accessing Open WebUI</h3>
        <p>To get started, navigate to the tinyllama.local landing page and click on &quot;Open WebUI&quot; to
            access the service. You'll be directed to a sign-in page.</p>
        <p><img src="sign_up.png" alt="Open WebUI Sign Up screen" class="fitImage"></p>
        <h3 id="creating-an-account">Creating an Account</h3>
        <p>If this is your first time accessing Open WebUI, you'll need to create an account. Click the
            &quot;Sign up&quot; button and enter your name, email address, and password. Please note that all
            account information and associated data will be stored securely on the device.</p>
        <h3 id="resolving-account-issues">Resolving Account Issues</h3>
        <p>If someone else has already created an account on this device, you may encounter a message indicating
            that an account activation is pending. In this case, the original account holder (listed as
            &quot;Admin&quot;) must log in and approve your new account to grant access. To resolve this issue,
            follow our <a href="#account-activation">Account Activation</a> procedure.</p>
        <p><img src="account_pending.png" class="fitImage" alt="Open WebUI Account Activation Pending screen">
        </p>
        <h2 id="account-activation">Account Activation</h2>
        <p>Follow these steps to activate an account.</p>
        <h3 id="access-the-administrator-panel">Access the Administrator Panel</h3>
        <p>Log in to Open WebUI with the administrator account (usually the first account created). Click on
            your profile icon and select &quot;Admin Panel&quot;.</p>
        <p><img src="admin_panel_location.png" class="fitImage" alt="Open WebUI Admin Panel Location"></p>
        <h3 id="step-2-promote-the-pending-user">Step 2: Promote the Pending User</h3>
        <p><img src="admin_panel_promote_user.png" class="fitImage"
                alt="Open WebUI Admin Panel Promote User screen"></p>
        <p>From the Admin Panel, locate the user account with a pending role. Click on the &quot;pending&quot;
            role to change it to the &quot;user&quot; role.</p>
        <p>If you want to grant additional permissions, click on the &quot;user&quot; role again to promote the
            account to the &quot;admin&quot; role. This will allow the user to access the Admin Panel and other
            configuration settings associated with Open WebUI.</p>
        <h2 id="how-to-chat">How to Chat</h2>
        <p><img src="how_to_chat.png" class="fitImage" alt="Open WebUI Chat screen"></p>
        <h3 id="step-1-starting-a-new-conversation">Step 1: Starting a New Conversation</h3>
        <p>To start a new conversation, click on the &quot;New Chat&quot; button in the top-left corner of the
            Open WebUI interface once you're logged in.</p>
        <h3 id="step-2-selecting-a-model">Step 2: Selecting a Model</h3>
        <p>From here, you can choose a model best suited to your task. By default, llama3.1 is selected, which is
            a great generalist model suitable for many day-to-day tasks. For more information on the purposes of
            other models, see our <a href="#model-selection">Model Selection</a> section.</p>
        <h3 id="step-3-sending-messages">Step 3: Sending Messages</h3>
        <p>To send a message, type it into the message field at the bottom of the window. You can also upload
            documents for reference during the conversation by clicking on the &quot;+&quot; icon on the left
            side of the message bar.</p>
        <aside class="warning-card">
            Note that due to memory limitations, the Tiny Llama AI Home Server (2024) is limited to a 2048 token
            context window, which is roughly equivalent to 1,500 words in total, including the entirety of the
            conversation. In many cases, it's preferable to only copy and paste relevant sections of a document.
        </aside>
        <h3 id="step-4-submitting-messages">Step 4: Submitting Messages</h3>
        <p>Once you've entered a message, click the up arrow to submit it to the LLM (Large Language Model).</p>
        <aside class="warning-card">
            Please wait 5-10 seconds for the model to load into memory for the initial response. Once loaded,
            the delay will be
            shortened to less than 1 second. The model will stay loaded in memory and waiting for responses for
            up to 5 minutes before freeing up that memory for other tasks.
        </aside>
        <h2 id="model-selection">Model Selection</h2>
        <p>To select a model, click on the model name at the top of the chat window. You can choose from several
            options, and you can even select multiple models using the "+" sign to simultaneously to compare
            their responses.</p>
        <h3 id="available-models">Available Models</h3>
        <p>By default, Tiny Llama ships with these models available for selection:</p>
        <h4 id="llama3-1">llama3.1</h4>
        <p>A generalist model developed by Meta, suitable for many day-to-day tasks. Llama 3.1 instruction-tuned
            models are fine-tuned and optimized for dialogue/chat use cases, outperforming most other open-source chat
            models on common benchmarks.</p>
        <h4 id="hermes-2-theta-llama-3">hermes-2-Theta-llama-3</h4>
        <p>An experimental merged model from Nous Research, offering uncensored conversations without content
            filters or ethical guidelines. This makes it ideal for highly creative endeavors and prompt
            suggestions, such as roleplay.</p>
        <h4 id="llava-phi3">llava-phi3</h4>
        <p>An LMM (Large Multi-modal Model) capable of reading/writing text and visual interpretation of image
            content. This model is great for transcribing text from images or basic scene interpretation.
            Ideally, it should used in conjunction with other models like llama3.1 for the best experience, as its
            visual component may detract the model from higher-quality reading and conversational comprehension.
        </p>
        <h2 id="image-inference-via-chat">Image Inference via Chat</h2>
        <h3 id="using-lmms-for-image-inference">Using LMMs for Image Inference</h3>
        <p><img src="image_request.png" class="fitImage" alt="Open WebUI image inference workflow"></p>
        <p>To perform image inference, follow these steps:</p>
        <ol>
            <li>Select a large multi-modal model capable of image inference, such as llava-phi3.</li>
            <li>Attach the image to the message box by either copying and pasting an image or clicking on the
                &quot;+&quot; icon and selecting &quot;Upload Files&quot;.</li>
        </ol>
        <p><img src="image_response.png" class="fitImage" alt="Open WebUI image inference response"></p>
        <aside class="warning-card">
            Keep in mind that while these models are improving at a fast rate, they're not perfect yet. However,
            you
            can still get great assistance with interpreting textual content like labels or mixed-media images
            that contain both text and image data. The more context you provide the model upfront, the better it
            will be at understanding the scene and providing a helpful response.
        </aside>
        <h2 id="image-generation-via-chat">Image Generation via Chat</h2>
        <img src="image_gen_prompt.png" class="fitImage" alt="Open WebUI image generation prompt">
        <h3 id="generating-images-with-diffusion-models-and-llms">Generating Images with Diffusion Models and
            LLMs
        </h3>
        <br />
        <p>Open-WebUI is configured for image generation inference by default, using
            <a class="external" href="https://civitai.com/models/15003?modelVersionId=372799"
                target="_blank">CyberRealistic V4.2</a> as its
            partner model. To generate an image with the assistance of your favorite Large Language Model (LLM),
            follow these steps:
        </p>
        <ol>
            <li>
                <p>Choose an LLM to collaborate with on your image generation journey. llama3.1 is a suitable
                    choice for most tasks.
                </p>
            </li>
            <li>
                <p>Provide a specific caption prompt, including adequate context to help the model understand
                    the task.</p>
            </li>
            <li>
                <p>Once you've written and edited the caption as needed, click the image icon to submit it to
                    SwarmUI for inference.</p>
            </li>
            <li>
                <p>Wait for the image generation process to complete. The generated image will appear above the
                    prompt. You can regenerate the image as many times as desired. If the caption doesn't quite
                    meet your expectations, feel free to edit the LLM's response using the pen icon or
                    regenerate the response and try again.</p>
            </li>
        </ol>
        <p><img src="image_gen_response.png" class="fitImage" alt="Open WebUI image generation icon"></p>
        <aside class="warning-card">
            The initial image generation may take up to 5-10 seconds depending on system utilization and prompt
            parameters. Subsequent generations typically complete within 4 seconds, as the diffusion model
            remains in memory for up to 1 minute. After 1 minute, the diffusion model is unloaded to make room
            for other models.
        </aside>
    </div>
</div>